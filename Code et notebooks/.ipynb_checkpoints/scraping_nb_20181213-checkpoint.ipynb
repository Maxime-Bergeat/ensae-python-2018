{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping des haïkus\n",
    "===========\n",
    "Objectif : scraper les haïkus, leur contenu et quelques informations sur les auteurs.\n",
    "\n",
    "Méthode : On utilise la liste des url d'haïkus écrits par des écrivains francophones. Cette liste a été préalablement extraite du site tempslibres.org. Il s'agit de télécharger chaque page, d'en extraire le poème à partir du repérage des balises HTML puis de les ranger dans un tableau de données exporté au format csv. Celui-ci sera enfin épluché afin de s'assurer que les haïkus correspondent à leur auteur, sont intègres, et sont en langue française.\n",
    "\n",
    "Difficultés : La difficulté principale réside dans la présence occasionnelle de plusieurs haïkus par page. En effet, certains haïkus sont écrits en plusieurs langues. Dans la perspective d'une analyse lexicale, il convient de les éliminer. Hélas, la place du poème français parmi les différents poèmes n'est pas fixe d'où le recours nécessaire à un dispositif de reconnaissance de la langue du texte.\n",
    "\n",
    "Le format du haïku rendant approximative la reconnaissance de la langue par la fréquence des lettres, nous avons opté pour un score calculé à partir de marques du français et de marques de langues étrangères, essentiellement des stopwords ainsi que certains accents.\n",
    "\n",
    "La phase de vérification a montré une efficacité de 100% de cette méthode, au sens où 100% des poèmes scrappés étaient en français alors que les cas de langues multiples étaient fréquents. Un poème mi-français mi-anglais a été retiré manuellement ensuite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données\n",
    "----------\n",
    "Deux tableaux de données sont utilisés :\n",
    "* la liste des URL des haïkus\n",
    "* le tableau de correspondance du nom de l'auteur et de son sexe, lequel a été saisi manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "##Liste des URL :\n",
    "bdd_url = pd.read_csv(\"liste_urls_haikus_auteurs_franco_V2_20181022.csv\")\n",
    "##Correspondance auteurs-sexes\n",
    "auteurs = pd.read_csv(\"Sexe_Auteurs_Haikus.csv\", sep=\",\")\n",
    "##Tableau de données à l'issue de l'extraction\n",
    "haikus=pd.DataFrame(columns=[\"url\",\"id_auteur\", \"auteur\", \"sexe\", \"pays\", \"haiku\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constitution des listes de marqueurs du français et des langues étrangères\n",
    "------\n",
    "Le problème des langues étrangères ne se posent que pour deux langues :\n",
    "1. l'anglais, très majoritairement\n",
    "2. l'espagnol, anecdotiquement\n",
    "\n",
    "Il a paru suffisant de faire un score unique, d'autant plus élevé que le texte possède de marques du français et d'autant plus bas qu'il contient des marques de l'anglais ou de l'espagnol.\n",
    "\n",
    "En plus des stopwords, on a rajouté des accents, y compris le \"é\" qui existe aussi en espagnol mais est moins fréquent qu'en français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words_fr = get_stop_words('french') \n",
    "stop_words_fr = [ \" \"+i+\" \" for i in stop_words_fr if len(i)>1] ## on espace les mots vides pour qu'ils ne soient pas comptablisés au sein d'un autre mot. Par exemple \"the\" ne doit pas être\n",
    "stop_words_fr += [\"é\", \"ê\", \"à\", \"è\", \"'a\", \"'à\", \"'u\", \"'e\", \"'o\", \"ç\"]\n",
    "stop_words_non_fr = get_stop_words('english') + get_stop_words('spanish')\n",
    "stop_words_non_fr = [ \" \"+i+\" \" for i in stop_words_non_fr if len(i)>1]\n",
    "stop_words_non_fr += [\"'s\", \"the\"]\n",
    "#print(stop_words_fr)\n",
    "#print(stop_words_non_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On boucle sur les URL\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%    i=0     Temps estimé : 0 minutes et 4 secondes\n",
      "==============================================================\n",
      "10.0%    i=1     Temps estimé : 0 minutes et 5 secondes\n",
      "==============================================================\n",
      "20.0%    i=2     Temps estimé : 0 minutes et 4 secondes\n",
      "==============================================================\n",
      "30.0%    i=3     Temps estimé : 0 minutes et 5 secondes\n",
      "==============================================================\n",
      "40.0%    i=4     Temps estimé : 0 minutes et 4 secondes\n",
      "==============================================================\n",
      "50.0%    i=5     Temps estimé : 0 minutes et 3 secondes\n",
      "==============================================================\n",
      "60.0%    i=6     Temps estimé : 0 minutes et 3 secondes\n",
      "==============================================================\n",
      "70.0%    i=7     Temps estimé : 0 minutes et 2 secondes\n",
      "==============================================================\n",
      "80.0%    i=8     Temps estimé : 0 minutes et 2 secondes\n",
      "==============================================================\n",
      "90.0%    i=9     Temps estimé : 0 minutes et 1 secondes\n",
      "==============================================================\n",
      "Nombre de poèmes scrapés : 10     Temps total : 0 minutes et 4 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>id_auteur</th>\n",
       "      <th>auteur</th>\n",
       "      <th>sexe</th>\n",
       "      <th>pays</th>\n",
       "      <th>haiku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.tempslibres.org/tl/tlphp/dbhk03.php...</td>\n",
       "      <td>quin-p</td>\n",
       "      <td>Philippe Quinta</td>\n",
       "      <td>H</td>\n",
       "      <td>France</td>\n",
       "      <td>Fut-elle pleine\\\\déjà, elle décroit\\\\la lune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.tempslibres.org/tl/tlphp/dbhk03.php...</td>\n",
       "      <td>py-d</td>\n",
       "      <td>Daniel Py</td>\n",
       "      <td>H</td>\n",
       "      <td>France</td>\n",
       "      <td>Lune parfaitement ronde\\\\Buée sur la vitre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.tempslibres.org/tl/tlphp/dbhk03.php...</td>\n",
       "      <td>alex-m</td>\n",
       "      <td>Marlène Alexa</td>\n",
       "      <td>F</td>\n",
       "      <td>Egypte</td>\n",
       "      <td>hiver\\\\dans les yeux de grand-mère\\\\une ombre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.tempslibres.org/tl/tlphp/dbhk03.php...</td>\n",
       "      <td>sang-r</td>\n",
       "      <td>Rahmatou Sangotte</td>\n",
       "      <td>F</td>\n",
       "      <td>France</td>\n",
       "      <td>ciel gris -\\\\une odeur d'oignons\\\\caramélisés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.tempslibres.org/tl/tlphp/dbhk03.php...</td>\n",
       "      <td>rais-c</td>\n",
       "      <td>Carol Raisfeld</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>la fille du pasteur\\\\sa robe du dimanche\\\\de l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url id_auteur  \\\n",
       "0  http://www.tempslibres.org/tl/tlphp/dbhk03.php...    quin-p   \n",
       "1  http://www.tempslibres.org/tl/tlphp/dbhk03.php...      py-d   \n",
       "2  http://www.tempslibres.org/tl/tlphp/dbhk03.php...    alex-m   \n",
       "3  http://www.tempslibres.org/tl/tlphp/dbhk03.php...    sang-r   \n",
       "4  http://www.tempslibres.org/tl/tlphp/dbhk03.php...    rais-c   \n",
       "\n",
       "              auteur sexe    pays  \\\n",
       "0    Philippe Quinta    H  France   \n",
       "1          Daniel Py    H  France   \n",
       "2      Marlène Alexa    F  Egypte   \n",
       "3  Rahmatou Sangotte    F  France   \n",
       "4     Carol Raisfeld    F     USA   \n",
       "\n",
       "                                               haiku  \n",
       "0       Fut-elle pleine\\\\déjà, elle décroit\\\\la lune  \n",
       "1         Lune parfaitement ronde\\\\Buée sur la vitre  \n",
       "2  hiver\\\\dans les yeux de grand-mère\\\\une ombre ...  \n",
       "3      ciel gris -\\\\une odeur d'oignons\\\\caramélisés  \n",
       "4  la fille du pasteur\\\\sa robe du dimanche\\\\de l...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrapper_sur_csv(jusqua=len(bdd_url)-1) :\n",
    "\t\"\"\"Écrit chaque haiku sur une ligne dans le fichier haikus.csv\"\"\"\n",
    "\ti = 0\n",
    "\ttimestamp_initial= time.time()\n",
    "\t###Afficher l'avancement pour les i suivants\n",
    "\ti_affiches = [int(i*jusqua) for i in np.linspace(start=0, stop=1, num=11)]\n",
    "\twhile i < jusqua :\n",
    "\t\turl_page = bdd_url.loc[i, \"URL\"]\n",
    "\t\tpage = request.urlopen(url_page).read()\n",
    "\t\tpage = bs4.BeautifulSoup(page, \"lxml\")\n",
    "\t\textrait = page.findAll('p', {'class' : 'dbhkanahaiku'}) ### le haïku se trouve dans un paragraphe de classe dbhkanahaiku\n",
    "\t\textrait = str(extrait) # objet BS → chaîne de caractères\n",
    "\t\t##On retire les balises parasites\n",
    "\t\textrait = extrait.split('class=\"dbhkanahaiku\">')[1] #la balise initiale\n",
    "\t\textrait = extrait.replace(\"</p>]\", \"\") #la balise finale\n",
    "\t\textrait = extrait.replace(\"<br/>\",\"\")\n",
    "\t\textrait = extrait.replace(\"\\r\", \"\")\n",
    "\t\t##Lorsqu'il y a plusieurs poèmes, ils sont séparés par un double saut de ligne, on les enregistre dans une liste\n",
    "\t\textrait = extrait.split(\"\\n\\n\")\n",
    "\t\t### AUTEUR, IDENTIFIANT, PAYS, SEXE\n",
    "\t\tauteur = page.findAll('p', {'class' : 'dbhktlref'})\n",
    "\t\tauteur=str(auteur)\n",
    "\t\t#print(auteur)\n",
    "\t\tauteur = auteur.split(\"<br/>\")[1]\n",
    "\t\tpays = auteur.split(\",\")[1]\n",
    "\t\tpays = pays.replace(\" \",\"\")\n",
    "\t\tauteur = auteur.split(\",\")[0]\n",
    "\t\tid_auteur = str(page).split(\"auteur=\")[1]\n",
    "\t\tid_auteur = id_auteur.split(\"&\")[0]\n",
    "\t\tid_auteur = id_auteur + \" \"\n",
    "\t\tsexe = auteurs[(auteurs[\"Page\"] == id_auteur)][\"Sexe\"] ##On utilise l'identifiant de l'auteur pour le retrouver dans le tableau de correspondance auteurs-sexes\n",
    "\t\tsexe = sexe.iloc[0]\n",
    "\t\tid_auteur = id_auteur.replace(\" \", \"\")\n",
    "\t\t#### Boucle pour calculer le score de langue de chaque poème de la liste\n",
    "\t\tj = 0\n",
    "\t\tscores = []\n",
    "\t\twhile j < len(extrait) :\n",
    "\t\t\thaiku = extrait[j].replace(\"\\n\", \"\\\\\\\\\")\n",
    "\t\t\tcontenu = haiku.replace(\"\\\\\\\\\", \" \")\n",
    "\t\t\tscore = 0 \n",
    "\t\t\tfor caract in stop_words_fr :\n",
    "\t\t\t\tscore = score + (caract in contenu)\n",
    "\t\t\tfor caract in stop_words_non_fr :\n",
    "\t\t\t\tscore = score - (caract in contenu)\n",
    "\t\t\t#print(url_page, contenu)\n",
    "\t\t\tscores.append(score)\n",
    "\t\t\t#print(scores[j])\n",
    "\t\t\tj += 1\n",
    "\t\tm = max(scores) ##On enregistre le score du poème le « plus » français\n",
    "\t\tif m > 0 : ##on ne prend le poème le « plus » français que si son score est positif, ie si le français l'emporte\n",
    "\t\t\tindice = [i for i, j in enumerate(scores) if j == m][0]\n",
    "\t\t\thaiku = extrait[indice].replace(\"\\n\", \"\\\\\\\\\") ##On adopte le signe \\\\ pour marquer les retours à la ligne\n",
    "\t\t\thaikus.loc[len(haikus)] = [url_page, id_auteur, auteur, sexe, pays, haiku] ## ajouter le poème à la liste\n",
    "\t\t##Calcul d'un pourcentage d'avancement de l'opération de scraping\n",
    "\t\tavancement = round(100*i/jusqua,1)\n",
    "\t\tif i in i_affiches:\n",
    "\t\t\ttimestamp_intermediaire = time.time()\n",
    "\t\t\tduree_moyenne = (timestamp_intermediaire-timestamp_initial)/(i+1)\n",
    "\t\t\tduree_restante = duree_moyenne*(jusqua+1-i)\n",
    "\t\t\tprint(avancement, \"%\", \"    \", \"i=\", i, \"     Temps estimé : \", int(round(duree_restante//60,0)), \" minutes et \", int(round(duree_restante%60,0)), \" secondes\", sep=\"\")\n",
    "\t\t\tprint(\"==============================================================\")\n",
    "\t\t\thaikus.to_csv(\"sauvegarde.csv\") ####on fait des sauvegardes régulières\n",
    "\t\ti += 1\n",
    "\tprint(\"Nombre de poèmes scrapés : \", jusqua, \"     Temps total : \", int((timestamp_intermediaire-timestamp_initial)//60), \" minutes et \", int((timestamp_intermediaire-timestamp_initial)%60), \" secondes\", sep=\"\")\n",
    "\thaikus.to_csv(\"haikus.csv\", index=False)\n",
    "\treturn(haikus)\n",
    "haikus = scrapper_sur_csv(jusqua=10) ## Tester sur les 10 premiers urls\n",
    "#scrapper_sur_csv() ## Tester sur tous les urls\n",
    "haikus.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
